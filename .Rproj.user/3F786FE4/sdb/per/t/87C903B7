{
    "contents" : "# LOAD TWITTER PACKAGE\nrequire(twitteR)\nrequire(ROAuth)\nt.api.key = \"pEMnGgZN2g61MsFGbdGOkX5RD\"\nt.api.secret = \"Sq9Z6VSm7PMuc6c9B75dunkg5StBQtzjxTa9BHkhsqjnTxxsl4\"\nt.api.accesstoken = \"2798804485-2aivg8zTXPNWcubok7JJWpHsocNCNnFb6U2H4IK\"\nt.api.accesssecret = \"GW9c5ZUs3mKku7fLb3Vgre0j8L60CG1FhjIxxhdcA6rgg\"\nt.reqURL = \"https://api.twitter.com/oauth/request_token\"\nt.accessURL = \"https://api.twitter.com/oauth/access_token\"\nt.authURL = \"https://api.twitter.com/oauth/authorize\"\n\nt.cred = \n  OAuthFactory$new(\n  consumerKey = t.api.key, \n  consumerSecret = t.api.secret,\n  requestURL = t.reqURL,\n  accessURL = t.accessURL, \n  authURL = t.authURL\n)\n\ndownload.file(url=\"http://curl.haxx.se/ca/cacert.pem\", destfile=\"cacert.pem\")\n\nt.cred$handshake(cainfo=\"cacert.pem\")\n\nsave(t.cred, file=\"twitcred\")\nt.cred <- load(\"twitcred\")\n\n# NEW WAY TO SETUP TWITTER\nsetup_twitter_oauth(t.api.key, t.api.secret, t.api.accesstoken, t.api.accesssecret)\n\n# A. GET TWEETS OF TWO STATES: BOSTON & PHILADELPHIA\ntwtBoston <- searchTwitter('#boston', n = 200)\ntwtPhila <- searchTwitter('#philadelphia', n = 200)\n\n# B. CREATE TWO DATA CORPUS FOR THE TWEETS\ngetCorpus <- function (tweets) {\n  tweets.text <- lapply(tweets, function(t) {t$getText()})\n  data.source <- VectorSource(tweets.text)\n  data.corpus <- Corpus(data.source)\n  return (data.corpus)\n}\n\ndata.t.boston = getCorpus(twtBoston)\ndata.t.phila = getCorpus(twtPhila)\n\n# C. PRE-PROCESS DATA\ngetTransCorpus <- function (data.corpus) {\n  data.corpus <- tm_map(data.corpus, content_transformer(removePunctuation))\n  data.corpus <- tm_map(data.corpus, content_transformer(tolower))\n  data.corpus <- tm_map(data.corpus, removeNumbers)\n  english.stopwords <- stopwords(\"en\")\n  removeURL <- function(x) gsub(\"http[[:alnum:]]*\", \"\", x)\n  data.corpus <- tm_map(data.corpus, content_transformer(removeURL))\n  data.corpus <- tm_map(data.corpus,content_transformer(removeWords),english.stopwords)\n  data.corpus <- tm_map(data.corpus,content_transformer(stemDocument))\n  data.corpus <- tm_map(data.corpus,content_transformer(stripWhitespace))\n  \n  return (data.corpus)\n}\n\ntdata.t.boston = getTransCorpus(data.t.boston)\ntdata.t.phila = getTransCorpus(data.t.phila)\n\n# D. CREATE TERM DOCUMENT MATRIX FOR EACH TWEET\ntdmBost <- TermDocumentMatrix(tdata.t.boston)\ntdmPhil <- TermDocumentMatrix(tdata.t.phila)\n\n# E. COMPARE FREQ TERMS IN EACH STATE\nmBost <- as.matrix(tdmBost)\nmPhil <- as.matrix(tdmPhil)\n\n# calculate the frequency of words \nWFBost <- rowSums(mBost)\nWFBost = sort(WFBost,decreasing = T)\n\nWFPhil <- rowSums(mPhil)\nWFPhil = sort(WFPhil,decreasing = T)\n\n# EXAMINE TOP TEN WORDS\ncbind(WFBost[1:10])\ncbind(WFPhil[1:10])\n\n# FREQ TERMS WITH LOWER FREQ BOUND OF 10\nfindFreqTerms(tdmBost, lowfreq=10)\nfindFreqTerms(tdmPhil, lowfreq=10)\n\n# F. GRAPHICAL WORDCLOUD OF THE FREQ WORDS\nrequire(wordcloud)\npalette = brewer.pal(8,\"Dark2\")\npar(mfrow=c(1,2))\nwordcloud(words = names(WFBost),\n          freq=WFBost,\n          min.freq=10,\n          random.order=F,\n          colors=palette)\n\nwordcloud(words = names(WFPhil),\n          freq=WFPhil,\n          min.freq=10,\n          random.order=F,\n          colors=palette)\npar(mfrow=c(1,1))\n\n# G. SENTIMENT ANALYSIS SCORE\nsentiment.na <- function(text, pos.words, neg.words) {\n  text <- gsub('[[:punct:]]', '', text)\n  text <- gsub('[[:cntrl:]]', '', text)\n  text <- gsub('\\\\d+', '', text)\n  text <- tolower(text)\n  # split the text into a vector of words\n  words <- strsplit(text, '\\\\s+')\n  words <- unlist(words)\n  # find which words are positive\n  pos.matches <- match(words, pos.words)\n  pos.matches <- !is.na(pos.matches)\n  # find which words are negative\n  neg.matches <- match(words, neg.words)\n  neg.matches <- !is.na(neg.matches)\n  # calculate the sentiment score\n  p <- sum(pos.matches)\n  n <- sum(neg.matches)\n  if (p == 0 & n == 0)\n    return (NA)\n  else\n    return (p - n)\n}\n\n# FETCH TEXT FROM TWEETS\nbost.texts <- \n  lapply(twtBoston, \n         function(t) {\n           iconv(t$getText(), \n                 \"latin1\", \"ASCII\", sub=\"\")\n         })\n\nphil.texts <- \n  lapply(twtPhila, \n         function(t) {\n           iconv(t$getText(), \n                 \"latin1\", \"ASCII\", sub=\"\")\n         })\n\n\n# GET SCORES\nbost.scores.na <- sapply(bost.texts, \n                    sentiment.na, \n                    pos.words, neg.words)\n\nphil.scores.na <- sapply(phil.texts, \n                         sentiment.na, \n                         pos.words, neg.words)\n\n\ntable(bost.scores.na)\n\ntable(phil.scores.na)\n\npar(mfrow=c(1,2))\n\nbarplot(table(bost.scores.na), main=\"Sentiment Analysis for Boston\",\n        xlab=\"Score\", ylab=\"Count\",\n        ylim=c(0,40), col=\"cyan\")\ngrid(nx=NA,ny=NULL,col=rgb(165,165,165,max=255),lty=1)\n\nbarplot(table(phil.scores.na), main=\"Sentiment Analysis for Philadelphia\",\n        xlab=\"Score\", ylab=\"Count\",\n        ylim=c(0,40), col=\"cyan\")\ngrid(nx=NA,ny=NULL,col=rgb(165,165,165,max=255),lty=1)\n\npar(mfrow=c(1,1))\n\n# Data frame of scores and tweets\n\nbost.vector <- sapply(bost.texts,function (t) {(t)})\nboston <- data.frame(Score=bost.scores.na, Text=bost.vector)\nView(boston)\n\nphil.vector <- sapply(phil.texts,function (t) {(t)})\nphiladelphia <- data.frame(Score=phil.scores.na, Text=phil.vector)\nView(philadelphia)\n",
    "created" : 1430340537578.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3174468791",
    "id" : "87C903B7",
    "lastKnownWriteTime" : 1430350714,
    "path" : "C:/Stuff/Downloads/MS BSAN/WA/Project Report/Code/5A.R",
    "project_path" : "5A.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}